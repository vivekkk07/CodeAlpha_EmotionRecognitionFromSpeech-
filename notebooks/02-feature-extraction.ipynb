{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction for Emotion Recognition\n",
    "\n",
    "In this notebook, we will focus on extracting features from audio data, specifically Mel-Frequency Cepstral Coefficients (MFCCs), which are commonly used in speech and audio processing tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import-libraries"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from src.features.mfcc import extract_mfcc\n",
    "from src.data.load_data import load_audio_files\n",
    "from src.data.preprocess import preprocess_audio\n",
    "\n",
    "# Set the path to the audio data\n",
    "audio_data_path = '../data/raw/'\n",
    "audio_files = load_audio_files(audio_data_path)\n",
    "\n",
    "# Display the loaded audio files\n",
    "print(f'Loaded {len(audio_files)} audio files from {audio_data_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "feature-extraction"
   },
   "outputs": [],
   "source": [
    "# Extract MFCC features from the audio files\n",
    "mfcc_features = []\n",
    "for file in audio_files:\n",
    "    audio, sr = librosa.load(file, sr=None)\n",
    "    audio = preprocess_audio(audio)\n",
    "    mfcc = extract_mfcc(audio, sr)\n",
    "    mfcc_features.append(mfcc)\n",
    "\n",
    "# Convert to a DataFrame for easier manipulation\n",
    "mfcc_df = pd.DataFrame(mfcc_features)\n",
    "mfcc_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing MFCC Features\n",
    "\n",
    "Let's visualize the MFCC features extracted from one of the audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualize-mfcc"
   },
   "outputs": [],
   "source": [
    "# Visualize MFCC features for the first audio file\n",
    "plt.figure(figsize=(10, 4))\n",
    "librosa.display.specshow(mfcc_df.iloc[0].values, x_axis='time')\n",
    "plt.colorbar()\n",
    "plt.title('MFCC Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we successfully extracted MFCC features from audio files, which will be used for training our emotion recognition models. Next steps will involve preparing the data for model training."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}